{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dakbuu/dak/blob/main/%EC%86%8C%EC%84%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Z4RIMl-Wel",
        "outputId": "a493e717-ff9e-405e-bccb-da4d144ad340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 데이터 파일 경로\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/API/db.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W9fTczUEUvoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# 중복 제거 및 문자열 인덱싱\n",
        "chars = list(set(data))\n",
        "char_to_index = {ch: i for i, ch in enumerate(sorted(chars))}\n",
        "index_to_char = {i: ch for i, ch in enumerate(sorted(chars))}\n",
        "\n",
        "# 입력 데이터와 타겟 데이터 생성\n",
        "max_len = 100\n",
        "step = 1\n",
        "input_chars = []\n",
        "target_chars = []\n",
        "\n",
        "for i in range(0, len(data) - max_len, step):\n",
        "    input_chars.append(data[i:i+max_len])\n",
        "    target_chars.append(data[i+max_len])\n",
        "\n",
        "# 입력 데이터와 타겟 데이터를 인덱스로 변환\n",
        "input_data = np.zeros((len(input_chars), max_len, len(chars)), dtype=np.float32)\n",
        "target_data = np.zeros((len(input_chars), len(chars)), dtype=np.float32)\n",
        "\n",
        "for i, (input_char, target_char) in enumerate(zip(input_chars, target_chars)):\n",
        "    for j, ch in enumerate(input_char):\n",
        "        input_data[i, j, char_to_index[ch]] = 1.0\n",
        "    target_data[i, char_to_index[target_char]] = 1.0\n"
      ],
      "metadata": {
        "id": "tGkRyFKZBm_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구현\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(256, input_shape=(max_len, len(chars))),\n",
        "    tf.keras.layers.Dense(len(chars), activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# 모델 학습\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "steps_per_epoch = len(input_chars) // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch {}/{}'.format(epoch+1, epochs))\n",
        "    loss = 0\n",
        "    \n",
        "    for step in range(steps_per_epoch):\n",
        "        i = random.randint(0, len(input_chars)-1)\n",
        "        input_batch = input_data[i:i+batch_size]\n",
        "        target_batch = target_data[i:i+batch_size]\n",
        "        \n",
        "        loss += model.train_on_batch(input_batch, target_batch)\n",
        "    \n",
        "    print('loss: {:.4f}'.format(loss / steps_per_epoch))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNqcnDEcBrws",
        "outputId": "8bfd86c2-1b26-48f2-e069-18e05caa1141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_1 (GRU)                 (None, 256)               636672    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 571)               146747    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 783,419\n",
            "Trainable params: 783,419\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "loss: 4.9592\n",
            "Epoch 2/20\n",
            "loss: 4.4332\n",
            "Epoch 3/20\n",
            "loss: 4.2361\n",
            "Epoch 4/20\n",
            "loss: 4.0068\n",
            "Epoch 5/20\n",
            "loss: 3.8174\n",
            "Epoch 6/20\n",
            "loss: 3.5893\n",
            "Epoch 7/20\n",
            "loss: 3.4342\n",
            "Epoch 8/20\n",
            "loss: 3.3960\n",
            "Epoch 9/20\n",
            "loss: 3.2483\n",
            "Epoch 10/20\n",
            "loss: 3.1229\n",
            "Epoch 11/20\n",
            "loss: 3.0152\n",
            "Epoch 12/20\n",
            "loss: 2.8807\n",
            "Epoch 13/20\n",
            "loss: 2.7320\n",
            "Epoch 14/20\n",
            "loss: 2.6208\n",
            "Epoch 15/20\n",
            "loss: 2.5609\n",
            "Epoch 16/20\n",
            "loss: 2.3267\n",
            "Epoch 17/20\n",
            "loss: 2.1804\n",
            "Epoch 18/20\n",
            "loss: 2.1036\n",
            "Epoch 19/20\n",
            "loss: 2.0210\n",
            "Epoch 20/20\n",
            "loss: 1.8540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/API')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ579ANFH_Ei",
        "outputId": "9560bb7c-dd75-4fe6-b86c-67cb4398a175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    }
  ]
}